{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple indexing on a grid within a circular region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gandalf_interations.gandalf_radial_iterator import gandalf_iterator\n",
    "\n",
    "# Hard-coded parameters (adjust these paths and values as needed)\n",
    "geom_file = \"path/to/your_file.geom\"       # Path to your .geom file\n",
    "cell_file = \"path/to/your_file.cell\"        # Path to your .cell file\n",
    "input_folder = \"path/to/your/input_folder\"  # Path to your input folder\n",
    "\n",
    "output_base = \"Xtal\"\n",
    "num_threads = 24\n",
    "max_radius = 1.8\n",
    "step = 0.5\n",
    "\n",
    "# Choose your peakfinder method: 'cxi', 'peakfinder9', or 'peakfinder8'\n",
    "peakfinder = 'cxi'\n",
    "\n",
    "# Define default peakfinder options.\n",
    "default_peakfinder_options = {\n",
    "    'cxi': \"--peaks=cxi\",\n",
    "    'peakfinder9': \"\"\"--peaks=peakfinder9\n",
    "--min-snr=1\n",
    "--min-snr-peak-pix=6\n",
    "--min-sig=9 \n",
    "--min-peak-over-neighbour=5\n",
    "--local-bg-radius=5\"\"\",\n",
    "    'peakfinder8': \"\"\"--peaks=peakfinder8\n",
    "--threshold=45\n",
    "--min-snr=3\n",
    "--min-pix-count=3\n",
    "--max-pix-count=500\n",
    "--local-bg-radius=9\n",
    "--min-res=30\n",
    "--max-res=500\"\"\"\n",
    "}\n",
    "\n",
    "# Other extra flags (as a multiline string)\n",
    "other_flags_str = \"\"\"--no-revalidate\n",
    "--no-half-pixel-shift\n",
    "--no-refine\n",
    "--no-non-hits-in-stream\"\"\"\n",
    "\n",
    "# Advanced indexing parameters\n",
    "min_peaks = 15\n",
    "tolerance = \"10,10,10,5\"\n",
    "xgandalf_sampling_pitch = 5\n",
    "xgandalf_grad_desc_iterations = 1\n",
    "xgandalf_tolerance = 0.02\n",
    "int_radius = \"2,5,10\"\n",
    "\n",
    "# Build flags\n",
    "other_flags = [line.strip() for line in other_flags_str.splitlines() if line.strip()]\n",
    "peakfinder_flags = [line.strip() for line in default_peakfinder_options[peakfinder].splitlines() if line.strip()]\n",
    "\n",
    "advanced_flags = [\n",
    "    f\"--min-peaks={min_peaks}\",\n",
    "    f\"--tolerance={tolerance}\",\n",
    "    f\"--xgandalf-sampling-pitch={xgandalf_sampling_pitch}\",\n",
    "    f\"--xgandalf-grad-desc-iterations={xgandalf_grad_desc_iterations}\",\n",
    "    f\"--xgandalf-tolerance={xgandalf_tolerance}\",\n",
    "    f\"--int-radius={int_radius}\"\n",
    "]\n",
    "\n",
    "# Fixed indexing flags (unchanged)\n",
    "indexing_flags = [\n",
    "    \"--indexing=xgandalf\",\n",
    "    \"--integration=rings\",\n",
    "]\n",
    "\n",
    "# Combine all flags\n",
    "flags_list = advanced_flags + other_flags + peakfinder_flags + indexing_flags\n",
    "\n",
    "# Display the parameters for verification.\n",
    "print(\"Running gandalf_iterator with the following parameters:\")\n",
    "print(\"Geom File:\", geom_file)\n",
    "print(\"Cell File:\", cell_file)\n",
    "print(\"Input Folder:\", input_folder)\n",
    "print(\"Output Base:\", output_base)\n",
    "print(\"Threads:\", num_threads)\n",
    "print(\"Max Radius:\", max_radius)\n",
    "print(\"Step:\", step)\n",
    "print(\"\\nCombined Flags:\", flags_list)\n",
    "\n",
    "# Run the indexing workflow\n",
    "try:\n",
    "    gandalf_iterator(\n",
    "        geom_file,\n",
    "        cell_file,\n",
    "        input_folder,\n",
    "        output_base,\n",
    "        num_threads,\n",
    "        max_radius=max_radius,\n",
    "        step=step,\n",
    "        extra_flags=flags_list\n",
    "    )\n",
    "    print(\"Indexing completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error during indexing:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.indexing_3d_histogram import plot3d_indexing_rate\n",
    "from visualization.indexing_center import indexing_heatmap\n",
    "\n",
    "# Hard-coded output folder path (adjust this path as needed)\n",
    "output_folder = \"path/to/your/output_folder\"\n",
    "\n",
    "print(\"Generating visualizations for output folder:\", output_folder)\n",
    "try:\n",
    "    # Call the visualization functions.\n",
    "    plot3d_indexing_rate(output_folder)\n",
    "    indexing_heatmap(output_folder)\n",
    "    print(\"Visualization completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error during visualization:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics processing cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_metrics.process_indexing_metrics import process_indexing_metrics\n",
    "\n",
    "# Hard-coded parameter values (adjust these as needed)\n",
    "stream_folder = \"path/to/your/stream_folder\"  # Path to your stream file folder\n",
    "wrmsd_tolerance = 2.0      # WRMSD tolerance (default: 2.0)\n",
    "indexing_tolerance = 4.0   # Indexing tolerance (default: 4.0)\n",
    "\n",
    "print(\"Processing metrics for folder:\", stream_folder)\n",
    "print(\"WRMSD Tolerance:\", wrmsd_tolerance)\n",
    "print(\"Indexing Tolerance:\", indexing_tolerance)\n",
    "\n",
    "try:\n",
    "    process_indexing_metrics(stream_folder, wrmsd_tolerance=wrmsd_tolerance, indexing_tolerance=indexing_tolerance)\n",
    "    print(\"Metrics processed successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error processing metrics:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and combine using calculated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Filter Separate Metrics Section -----\n",
    "import matplotlib.pyplot as plt\n",
    "from filter_and_combine.interactive_iqm import read_metric_csv, get_metric_ranges, filter_rows\n",
    "\n",
    "# ----- Parameter Setup & CSV Loading -----\n",
    "CSV_PATH = \"path/to/your/metrics.csv\"  # Adjust this path as needed\n",
    "\n",
    "print(\"Loading CSV file:\", CSV_PATH)\n",
    "grouped_data = read_metric_csv(CSV_PATH, group_by_event=True)\n",
    "all_rows = [row for rows in grouped_data.values() for row in rows]\n",
    "print(f\"Loaded {len(all_rows)} rows from CSV.\")\n",
    "\n",
    "# Define metrics to be analyzed.\n",
    "metrics_in_order = [\n",
    "    'weighted_rmsd',\n",
    "    'fraction_outliers',\n",
    "    'length_deviation',\n",
    "    'angle_deviation',\n",
    "    'peak_ratio',\n",
    "    'percentage_unindexed'\n",
    "]\n",
    "\n",
    "# ----- Compute Default Ranges & Set Thresholds -----\n",
    "# Compute ranges for each metric from the loaded data.\n",
    "ranges_dict = get_metric_ranges(all_rows, metrics=metrics_in_order)\n",
    "print(\"\\nMetric ranges (min, max):\")\n",
    "for m in metrics_in_order:\n",
    "    print(f\"  {m}: {ranges_dict[m]}\")\n",
    "\n",
    "# Set thresholds for each metric.\n",
    "# By default, thresholds are set to the maximum value from the data.\n",
    "# To adjust a threshold, simply modify the corresponding value in the THRESHOLDS dictionary.\n",
    "THRESHOLDS = {metric: ranges_dict[metric][1] for metric in metrics_in_order}\n",
    "# Example adjustment:\n",
    "# THRESHOLDS['weighted_rmsd'] = 10.0\n",
    "\n",
    "print(\"\\nUsing thresholds:\")\n",
    "for m in metrics_in_order:\n",
    "    print(f\"  {m}: {THRESHOLDS[m]}\")\n",
    "\n",
    "# ----- Filter Data & Plot Histograms -----\n",
    "filtered_separate = filter_rows(all_rows, THRESHOLDS)\n",
    "print(f\"\\nFiltering: {len(all_rows)} total rows -> {len(filtered_separate)} pass thresholds.\")\n",
    "\n",
    "if filtered_separate:\n",
    "    # Plot histograms for each metric.\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for i, metric in enumerate(metrics_in_order):\n",
    "        values = [r[metric] for r in filtered_separate if metric in r]\n",
    "        axes[i].hist(values, bins=20)\n",
    "        axes[i].set_title(f\"Histogram of {metric}\")\n",
    "        axes[i].set_xlabel(metric)\n",
    "        axes[i].set_ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No rows passed the thresholds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Combine Metrics & Filter Section -----\n",
    "import matplotlib.pyplot as plt\n",
    "from filter_and_combine.interactive_iqm import create_combined_metric, select_best_results_by_event, write_filtered_csv\n",
    "\n",
    "print(\"\\n--- Combined Metric Creation & Filtering ---\")\n",
    "# Define weights for each metric (adjust as needed; default is all zeros here)\n",
    "weights = {metric: 0.0 for metric in metrics_in_order}\n",
    "# Optionally, set some non-zero weights, for example:\n",
    "# weights = {'weighted_rmsd': 0.5, 'fraction_outliers': 0.2, 'length_deviation': 0.1, 'angle_deviation': 0.1, 'peak_ratio': 0.05, 'percentage_unindexed': 0.05}\n",
    "\n",
    "# Create the combined metric in the data rows\n",
    "create_combined_metric(\n",
    "    rows=all_rows,\n",
    "    metrics_to_combine=metrics_in_order,\n",
    "    weights=[weights[m] for m in metrics_in_order],\n",
    "    new_metric_name=\"combined_metric\"\n",
    ")\n",
    "\n",
    "# Determine range of the combined metric\n",
    "combined_vals = [r[\"combined_metric\"] for r in all_rows if \"combined_metric\" in r]\n",
    "if combined_vals:\n",
    "    cmin, cmax = min(combined_vals), max(combined_vals)\n",
    "    # Set threshold to the max value by default (adjust as needed)\n",
    "    combined_threshold = cmax\n",
    "    print(f\"Combined metric created successfully!\")\n",
    "    print(f\"  * Min value: {cmin:.3f}\")\n",
    "    print(f\"  * Max value: {cmax:.3f}\")\n",
    "else:\n",
    "    print(\"Failed to create combined metric. Check your weights.\")\n",
    "\n",
    "# Filter rows by the combined metric threshold\n",
    "filtered_combined = [r for r in all_rows if \"combined_metric\" in r and r[\"combined_metric\"] <= combined_threshold]\n",
    "print(f\"Filtering rows by combined_metric â‰¤ {combined_threshold:.3f}\")\n",
    "if not filtered_combined:\n",
    "    print(\"No rows passed the combined metric threshold.\")\n",
    "else:\n",
    "    # Group the filtered rows by event number\n",
    "    grouped_filtered = {}\n",
    "    for r in filtered_combined:\n",
    "        event = r.get(\"event_number\")\n",
    "        if event not in grouped_filtered:\n",
    "            grouped_filtered[event] = []\n",
    "        grouped_filtered[event].append(r)\n",
    "    \n",
    "    best_filtered = select_best_results_by_event(grouped_filtered, sort_metric=\"combined_metric\")\n",
    "    print(f\"{len(filtered_combined)} rows passed threshold, {len(best_filtered)} best rows selected per event.\")\n",
    "    \n",
    "    # Write the best filtered rows to a CSV file\n",
    "    write_filtered_csv(best_filtered, FILTERED_CSV_PATH)\n",
    "    print(f\"Wrote {len(best_filtered)} best-filtered rows to {FILTERED_CSV_PATH}\")\n",
    "    \n",
    "    # Plot histogram for the combined metric from the best rows\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    values = [r[\"combined_metric\"] for r in best_filtered]\n",
    "    plt.hist(values, bins=20)\n",
    "    plt.title(\"Histogram of Best Rows (combined_metric)\")\n",
    "    plt.xlabel(\"combined_metric\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Write Filter & Combine Results CSV to STREAM -----\n",
    "import os\n",
    "import time\n",
    "from filter_and_combine.csv_to_stream import write_stream_from_filtered_csv\n",
    "from filter_and_combine.interactive_iqm import read_metric_csv\n",
    "\n",
    "print(\"\\n--- Converting to Stream ---\")\n",
    "# Create output directory for the stream file (subfolder 'filtered_metrics' in the CSV directory)\n",
    "output_dir = os.path.join(os.path.dirname(CSV_PATH), 'filtered_metrics')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the output stream file path\n",
    "OUTPUT_STREAM_PATH = os.path.join(output_dir, 'filtered_metrics.stream')\n",
    "\n",
    "print(\"Starting conversion to stream file...\")\n",
    "time.sleep(0.2)\n",
    "print(\"  * Step 1/5: Reading filtered CSV file...\")\n",
    "filtered_grouped_data = read_metric_csv(FILTERED_CSV_PATH, group_by_event=True)\n",
    "time.sleep(0.2)\n",
    "\n",
    "print(\"  * Step 2/5: Checking for combined metric and selecting best rows (if applicable)...\")\n",
    "time.sleep(0.2)\n",
    "\n",
    "print(\"  * Step 3/5: (Best rows selection already performed in previous cell)\")\n",
    "time.sleep(0.2)\n",
    "\n",
    "print(\"  * Step 4/5: Writing the .stream file...\")\n",
    "write_stream_from_filtered_csv(\n",
    "    filtered_csv_path=FILTERED_CSV_PATH,\n",
    "    output_stream_path=OUTPUT_STREAM_PATH,\n",
    "    event_col=\"event_number\",\n",
    "    streamfile_col=\"stream_file\"\n",
    ")\n",
    "time.sleep(0.2)\n",
    "\n",
    "print(\"  * Step 5/5: Conversion complete!\")\n",
    "print(f\"CSV has been successfully converted to:\\n  {OUTPUT_STREAM_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Merging Section -----\n",
    "import time\n",
    "from merge_and_convert.merge import merge\n",
    "\n",
    "# Define the parameters for merging.\n",
    "stream_file = \"path/to/your/file.stream\"  # Path to the .stream file\n",
    "pointgroup = \"P212121\"  # Adjust pointgroup as needed\n",
    "num_threads = 24\n",
    "iterations = 5\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MERGING SECTION\")\n",
    "print(\"=\"*50)\n",
    "print(\"Merging in progress...\")\n",
    "time.sleep(0.2)  # Simulate progress\n",
    "\n",
    "# Call the merge function\n",
    "output_dir = merge(\n",
    "    stream_file,\n",
    "    pointgroup=pointgroup,\n",
    "    num_threads=num_threads,\n",
    "    iterations=iterations,\n",
    ")\n",
    "time.sleep(0.2)\n",
    "\n",
    "if output_dir is not None:\n",
    "    print(\"Merging done. Results are in:\", output_dir)\n",
    "else:\n",
    "    print(\"Merging failed. Please check the parameters and try again.\")\n",
    "print(\"Done merging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SHELX Conversion Section -----\n",
    "from merge_and_convert.convert_hkl_crystfel_to_shelx import convert_hkl_crystfel_to_shelx \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SHELX CONVERSION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if output_dir is None:\n",
    "    print(\"No merged output available. Please run the merge step first.\")\n",
    "else:\n",
    "    print(\"Converting to SHELX...\")\n",
    "    convert_hkl_crystfel_to_shelx(output_dir)\n",
    "    print(\"Conversion to SHELX completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- MTZ Conversion Section -----\n",
    "import os\n",
    "from merge_and_convert.convert_hkl_to_mtz import convert_hkl_to_mtz\n",
    "# Define the cell file path for MTZ conversion.\n",
    "cell_file = \"path/to/your/cell_file.cell\"  # Adjust as needed\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MTZ CONVERSION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if output_dir is None:\n",
    "    print(\"No merged output available. Please run the merge step first.\")\n",
    "else:\n",
    "    if not os.path.exists(cell_file):\n",
    "        print(\"Cell file not found. Please check the path:\", cell_file)\n",
    "    else:\n",
    "        print(\"Converting to MTZ...\")\n",
    "        convert_hkl_to_mtz(output_dir, cellfile_path=cell_file)\n",
    "        print(\"Conversion to MTZ completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyxem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
